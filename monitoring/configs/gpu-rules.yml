groups:
- name: gpu.rules
  rules:
  - alert: GPUHighTemperature
    expr: DCGM_FI_DEV_GPU_TEMP > 80
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "GPU {{ $labels.gpu }} temperature is high"
      description: "GPU {{ $labels.gpu }} temperature is {{ $value }}째C, which is above the warning threshold of 80째C."

  - alert: GPUCriticalTemperature
    expr: DCGM_FI_DEV_GPU_TEMP > 90
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "GPU {{ $labels.gpu }} temperature is critical"
      description: "GPU {{ $labels.gpu }} temperature is {{ $value }}째C, which is above the critical threshold of 90째C."

  - alert: GPUHighUtilization
    expr: DCGM_FI_DEV_GPU_UTIL > 95
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "GPU {{ $labels.gpu }} utilization is very high"
      description: "GPU {{ $labels.gpu }} utilization is {{ $value }}%, which has been above 95% for more than 5 minutes."

  - alert: GPUMemoryHigh
    expr: (DCGM_FI_DEV_FB_USED / DCGM_FI_DEV_FB_TOTAL) * 100 > 90
    for: 3m
    labels:
      severity: warning
    annotations:
      summary: "GPU {{ $labels.gpu }} memory usage is high"
      description: "GPU {{ $labels.gpu }} memory usage is {{ $value }}%, which is above 90%."

  - alert: GPUPowerConsumptionHigh
    expr: DCGM_FI_DEV_POWER_USAGE > 300
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "GPU {{ $labels.gpu }} power consumption is high"
      description: "GPU {{ $labels.gpu }} power consumption is {{ $value }}W, which is above 300W for more than 5 minutes."

  - alert: GPUDown
    expr: up{job="nvidia-gpu-exporter"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "GPU exporter is down"
      description: "NVIDIA GPU exporter has been down for more than 1 minute."

  - alert: DCGMExporterDown
    expr: up{job="dcgm-exporter"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "DCGM exporter is down"
      description: "DCGM exporter has been down for more than 1 minute."

  - alert: GPUThrottling
    expr: DCGM_FI_DEV_CLOCK_THROTTLE_REASONS > 0
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "GPU {{ $labels.gpu }} is being throttled"
      description: "GPU {{ $labels.gpu }} is being throttled due to reasons: {{ $value }}."

  - alert: GPUErrorsDetected
    expr: increase(DCGM_FI_DEV_ECC_SBE_AGG_TOTAL[5m]) > 0 or increase(DCGM_FI_DEV_ECC_DBE_AGG_TOTAL[5m]) > 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "GPU {{ $labels.gpu }} errors detected"
      description: "GPU {{ $labels.gpu }} has detected ECC errors in the last 5 minutes."

- name: gameforge.gpu.rules
  rules:
  - alert: GameForgeAIServiceGPUStarvation
    expr: (avg(DCGM_FI_DEV_GPU_UTIL) by (gpu) < 20) and on() (rate(gameforge_ai_requests_total[5m]) > 10)
    for: 3m
    labels:
      severity: warning
    annotations:
      summary: "GameForge AI service may be GPU starved"
      description: "AI service is receiving requests but GPU utilization is low, indicating potential GPU allocation issues."

  - alert: GameForgeAIModelInferenceLatencyHigh
    expr: gameforge_ai_inference_latency_seconds > 2.0
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "GameForge AI inference latency is high"
      description: "AI model inference latency is {{ $value }}s, which exceeds the 2s threshold."

  - alert: GameForgeGPUClusterDegraded
    expr: (count(up{job="nvidia-gpu-exporter"} == 1) / count(up{job="nvidia-gpu-exporter"})) * 100 < 80
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "GameForge GPU cluster is degraded"
      description: "Only {{ $value }}% of GPUs are available, which is below the 80% threshold."
