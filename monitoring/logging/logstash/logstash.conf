# Logstash Configuration for GameForge
input {
  beats {
    port => 5044
    host => "0.0.0.0"
  }

  # Kafka input for real-time events
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["gameforge-events", "gameforge-metrics", "gameforge-security"]
    group_id => "logstash-gameforge"
    codec => json
  }

  # HTTP input for API logs
  http {
    port => 8080
    host => "0.0.0.0"
    codec => json
  }

  # TCP input for syslog
  tcp {
    port => 5140
    type => syslog
  }
}

filter {
  # Add timestamp
  if ![timestamp] {
    mutate { add_field => { "timestamp" => "%{@timestamp}" } }
  }

  # Parse GameForge application logs
  if [service] == "gameforge" and [log_type] == "application" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:log_timestamp} %{LOGLEVEL:level} %{DATA:logger} - %{GREEDYDATA:log_message}" 
      }
    }

    # Extract additional fields for API logs
    if [log_message] =~ /^(GET|POST|PUT|DELETE|PATCH)/ {
      grok {
        match => { 
          "log_message" => "%{WORD:http_method} %{URIPATH:endpoint} %{NUMBER:response_code:int} %{NUMBER:response_time:float}ms" 
        }
      }
      mutate { add_tag => ["api_request"] }
    }

    # Extract user information
    if [log_message] =~ /user_id/ {
      grok {
        match => { 
          "log_message" => ".*user_id=(?<user_id>[^\s]+)" 
        }
      }
    }

    # Extract game session information
    if [log_message] =~ /session_id/ {
      grok {
        match => { 
          "log_message" => ".*session_id=(?<session_id>[^\s]+)" 
        }
      }
    }
  }

  # Parse GPU logs
  if [component] == "nvidia" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:log_timestamp}.*GPU %{NUMBER:gpu_id:int}.*temperature=%{NUMBER:temperature:float}.*utilization=%{NUMBER:utilization:float}" 
      }
    }
    mutate { add_tag => ["gpu_metrics"] }
  }

  # Parse security logs
  if [log_type] == "security" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:log_timestamp} %{LOGLEVEL:level} %{DATA:security_event} user=%{DATA:user} ip=%{IP:client_ip} action=%{DATA:action}" 
      }
    }

    # GeoIP lookup for client IP
    geoip {
      source => "client_ip"
      target => "geoip"
      add_tag => ["geoip"]
    }

    mutate { add_tag => ["security_event"] }
  }

  # Parse business analytics logs
  if [log_type] == "business" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:log_timestamp}.*event=%{DATA:business_event}.*value=%{NUMBER:business_value:float}.*currency=%{DATA:currency}" 
      }
    }
    mutate { add_tag => ["business_metrics"] }
  }

  # Parse web server access logs
  if [component] == "webserver" {
    grok {
      match => { 
        "message" => "%{IPORHOST:client_ip} - - \[%{HTTPDATE:timestamp}\] "%{WORD:http_method} %{URIPATH:endpoint} HTTP/%{NUMBER:http_version}" %{NUMBER:response_code:int} %{NUMBER:bytes:int} "%{DATA:referrer}" "%{DATA:user_agent}"" 
      }
    }

    # GeoIP lookup
    geoip {
      source => "client_ip"
      target => "geoip"
    }

    mutate { add_tag => ["web_access"] }
  }

  # Parse database logs
  if [component] == "database" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:log_timestamp}.*\[%{LOGLEVEL:level}\].*%{GREEDYDATA:db_message}" 
      }
    }

    # Extract slow query information
    if [db_message] =~ /slow query/ {
      grok {
        match => { 
          "db_message" => ".*Query_time: %{NUMBER:query_time:float}.*Lock_time: %{NUMBER:lock_time:float}.*Rows_sent: %{NUMBER:rows_sent:int}.*Rows_examined: %{NUMBER:rows_examined:int}" 
        }
      }
      mutate { add_tag => ["slow_query"] }
    }

    mutate { add_tag => ["database"] }
  }

  # ML Anomaly Detection Processing
  if "api_request" in [tags] {
    # Calculate request rate anomalies
    aggregate {
      task_id => "%{endpoint}"
      code => "
        map['count'] ||= 0
        map['count'] += 1
        map['sum_response_time'] ||= 0
        map['sum_response_time'] += event.get('response_time').to_f
        map['avg_response_time'] = map['sum_response_time'] / map['count']
        event.set('avg_response_time', map['avg_response_time'])
        event.set('request_count', map['count'])
      "
      push_previous_map_as_event => true
      timeout => 60
    }

    # Mark anomalous response times
    if [response_time] and [avg_response_time] {
      ruby {
        code => "
          response_time = event.get('response_time').to_f
          avg_response_time = event.get('avg_response_time').to_f

          if avg_response_time > 0 and response_time > (avg_response_time * 2)
            event.set('anomaly_type', 'high_response_time')
            event.tag('anomaly')
          end
        "
      }
    }
  }

  # Security threat detection
  if "security_event" in [tags] {
    # Detect brute force attempts
    aggregate {
      task_id => "%{client_ip}"
      code => "
        map['failed_attempts'] ||= 0
        if event.get('action') == 'login_failed'
          map['failed_attempts'] += 1
        end

        if map['failed_attempts'] > 5
          event.set('threat_type', 'brute_force')
          event.tag('security_threat')
        end
      "
      push_previous_map_as_event => true
      timeout => 300
    }
  }

  # Data enrichment
  mutate {
    add_field => { 
      "processing_timestamp" => "%{@timestamp}"
      "logstash_version" => "8.11.0"
      "pipeline" => "gameforge-main"
    }
  }

  # Convert numeric fields
  mutate {
    convert => {
      "response_time" => "float"
      "response_code" => "integer"
      "temperature" => "float"
      "utilization" => "float"
      "business_value" => "float"
      "query_time" => "float"
      "lock_time" => "float"
      "rows_sent" => "integer"
      "rows_examined" => "integer"
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => ["beat", "prospector", "input", "host"]
  }
}

output {
  # Main Elasticsearch output
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "gameforge-%{log_type}-%{+YYYY.MM.dd}"
    template_name => "gameforge"
    template_pattern => "gameforge-*"
    template => "/usr/share/logstash/templates/gameforge-template.json"
    user => "logstash_system"
    password => "${LOGSTASH_SYSTEM_PASSWORD}"
  }

  # Security events to dedicated index
  if "security_event" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "gameforge-security-%{+YYYY.MM.dd}"
      user => "logstash_system"
      password => "${LOGSTASH_SYSTEM_PASSWORD}"
    }
  }

  # Anomalies to ML index
  if "anomaly" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "gameforge-anomalies-%{+YYYY.MM.dd}"
      user => "logstash_system"
      password => "${LOGSTASH_SYSTEM_PASSWORD}"
    }
  }

  # Business metrics to time-series database
  if "business_metrics" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "gameforge-business-%{+YYYY.MM.dd}"
      user => "logstash_system"
      password => "${LOGSTASH_SYSTEM_PASSWORD}"
    }
  }

  # Debug output (comment out in production)
  # stdout { codec => rubydebug }
}
