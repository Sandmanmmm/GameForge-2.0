# OpenTelemetry Collector Configuration for GameForge
# Comprehensive observability pipeline for AI/ML and game workloads

receivers:
  # OTLP receiver for traces, metrics, and logs
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  # Prometheus receiver for scraping metrics
  prometheus:
    config:
      scrape_configs:
        - job_name: 'gameforge-app'
          static_configs:
            - targets: ['gameforge-app:8080']
          scrape_interval: 30s
          metrics_path: /metrics

        - job_name: 'gameforge-gpu-inference'
          static_configs:
            - targets: ['gameforge-gpu-inference:8080']
          scrape_interval: 15s
          metrics_path: /metrics

        - job_name: 'gameforge-gpu-training'
          static_configs:
            - targets: ['gameforge-gpu-training:8080']
          scrape_interval: 30s
          metrics_path: /metrics

        - job_name: 'mlflow-server'
          static_configs:
            - targets: ['mlflow-server:5000']
          scrape_interval: 30s
          metrics_path: /metrics

  # Host metrics receiver
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
      disk:
      filesystem:
      network:
      process:

  # Docker stats receiver
  docker_stats:
    endpoint: unix:///var/run/docker.sock
    collection_interval: 30s
    timeout: 10s

processors:
  # Batch processor for performance
  batch:
    timeout: 1s
    send_batch_size: 1024
    send_batch_max_size: 2048

  # Memory limiter to prevent OOM
  memory_limiter:
    limit_mib: 512
    spike_limit_mib: 128
    check_interval: 5s

  # Resource processor to add/modify resource attributes
  resource:
    attributes:
      - key: deployment.environment
        value: "production"
        action: upsert
      - key: service.namespace
        value: "gameforge"
        action: upsert

  # Attributes processor for trace enrichment
  attributes:
    actions:
      - key: http.user_agent
        action: delete
      - key: http.request.header.authorization
        action: delete
      - key: sensitive_data
        action: delete

  # Probabilistic sampler for traces (10% sampling)
  probabilistic_sampler:
    sampling_percentage: 10.0

  # Tail sampling for critical traces
  tail_sampling:
    decision_wait: 10s
    num_traces: 100
    expected_new_traces_per_sec: 10
    policies:
      - name: errors
        type: status_code
        status_code: {status_codes: [ERROR]}
      - name: high_latency
        type: latency
        latency: {threshold_ms: 1000}
      - name: ml_operations
        type: string_attribute
        string_attribute: {key: "operation.type", values: ["ml.inference", "ml.training", "model.load"]}

  # Transform processor for custom metrics
  transform:
    metric_statements:
      - context: metric
        statements:
          - set(description, "GameForge custom metric") where name == "gameforge_custom"

exporters:
  # OTLP exporter for traces to Jaeger
  otlp/jaeger:
    endpoint: jaeger:14250
    tls:
      insecure: true

  # Prometheus exporter for metrics
  prometheus:
    endpoint: "0.0.0.0:8889"
    const_labels:
      environment: "production"
      service: "gameforge"

  # OTLP exporter for logs (to be sent to Elasticsearch via Logstash)
  otlp/logs:
    endpoint: http://logstash:8080
    tls:
      insecure: true

  # Debug exporter for troubleshooting
  debug:
    verbosity: basic

  # File exporter for backup
  file:
    path: /data/otel-output.json
    rotation:
      max_megabytes: 100
      max_days: 3
      max_backups: 10

extensions:
  # Health check extension
  health_check:
    endpoint: 0.0.0.0:13133

  # pprof extension for performance profiling
  pprof:
    endpoint: 0.0.0.0:1777

  # zpages extension for diagnostics
  zpages:
    endpoint: 0.0.0.0:55679

service:
  extensions: [health_check, pprof, zpages]
  
  pipelines:
    # Traces pipeline
    traces:
      receivers: [otlp]
      processors: [memory_limiter, resource, attributes, probabilistic_sampler, tail_sampling, batch]
      exporters: [otlp/jaeger, debug]

    # Metrics pipeline
    metrics:
      receivers: [otlp, prometheus, hostmetrics, docker_stats]
      processors: [memory_limiter, resource, transform, batch]
      exporters: [prometheus, debug]

    # Logs pipeline
    logs:
      receivers: [otlp]
      processors: [memory_limiter, resource, attributes, batch]
      exporters: [otlp/logs, debug]

  # Telemetry configuration
  telemetry:
    logs:
      level: "info"
    metrics:
      address: 0.0.0.0:8888
