# GameForge GPU Workload Dockerfile - Optimized for NVIDIA GPU Compute
# ========================================================================
# Multi-stage build for optimized GPU inference and training workloads
# ========================================================================

ARG CUDA_VERSION=12.1
ARG CUDNN_VERSION=8
ARG UBUNTU_VERSION=22.04
ARG PYTHON_VERSION=3.10

# ========================================================================
# Stage 1: NVIDIA CUDA Base with PyTorch
# ========================================================================
FROM nvidia/cuda:${CUDA_VERSION}-cudnn${CUDNN_VERSION}-devel-ubuntu${UBUNTU_VERSION} AS cuda-base

# Prevent interactive prompts during build
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV PIP_NO_CACHE_DIR=1
ENV PIP_DISABLE_PIP_VERSION_CHECK=1

# NVIDIA Container Runtime environment
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility
ENV NVIDIA_REQUIRE_CUDA="cuda>=12.0"

# Install system dependencies for GPU compute
RUN apt-get update && apt-get install -y --no-install-recommends \
    python${PYTHON_VERSION} \
    python${PYTHON_VERSION}-dev \
    python3-pip \
    python3-venv \
    build-essential \
    cmake \
    git \
    curl \
    wget \
    unzip \
    libssl-dev \
    libffi-dev \
    libjpeg-dev \
    libpng-dev \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    libopenblas-dev \
    libnccl2 \
    libnccl-dev \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Install NVIDIA tools for monitoring
RUN apt-get update && apt-get install -y --no-install-recommends \
    nvidia-utils-525 \
    nvidia-ml-py3 \
    && rm -rf /var/lib/apt/lists/*

# ========================================================================
# Stage 2: Python Dependencies for GPU Workloads
# ========================================================================
FROM cuda-base AS gpu-deps

# Create and activate virtual environment
RUN python${PYTHON_VERSION} -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Install PyTorch with CUDA support
RUN pip install --upgrade pip setuptools wheel && \
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Install additional GPU-accelerated libraries
RUN pip install --no-cache-dir \
    nvidia-ml-py3==12.535.77 \
    nvidia-cuda-runtime-cu12==12.1.105 \
    nvidia-cuda-cupti-cu12==12.1.105 \
    nvidia-cublas-cu12==12.1.3.1 \
    nvidia-curand-cu12==10.3.2.106 \
    nvidia-cusolver-cu12==11.4.5.107 \
    nvidia-cusparse-cu12==12.1.0.106 \
    nvidia-nccl-cu12==2.18.1 \
    nvidia-nvjitlink-cu12==12.3.52

# Install ML/AI libraries optimized for GPU
RUN pip install --no-cache-dir \
    transformers==4.35.0 \
    accelerate==0.24.1 \
    datasets==2.14.6 \
    tokenizers==0.14.1 \
    diffusers==0.21.4 \
    xformers==0.0.22 \
    bitsandbytes==0.41.2.post2 \
    peft==0.6.2 \
    trl==0.7.4 \
    optimum==1.13.2

# Install monitoring and profiling tools
RUN pip install --no-cache-dir \
    tensorboard==2.14.1 \
    wandb==0.15.12 \
    mlflow==2.7.1 \
    pytorch-lightning==2.1.0 \
    deepspeed==0.11.2

# Copy requirements files
COPY requirements.txt requirements-gpu.txt* ./

# Install application-specific requirements
RUN pip install --no-cache-dir -r requirements.txt && \
    if [ -f requirements-gpu.txt ]; then \
        pip install --no-cache-dir -r requirements-gpu.txt; \
    fi

# ========================================================================
# Stage 3: Security and User Setup
# ========================================================================
FROM gpu-deps AS secure-gpu

# Security: Create non-root user with specific UID/GID
RUN groupadd -g 1001 gameforge && \
    useradd -u 1001 -g gameforge -m -s /bin/bash gameforge && \
    mkdir -p /home/gameforge/.local/bin

# Create application directories with proper permissions
RUN mkdir -p \
    /app/logs \
    /app/cache \
    /app/assets \
    /app/generated_assets \
    /app/models_cache \
    /app/checkpoints \
    /app/training_data \
    /app/tmp \
    /app/monitoring && \
    chown -R gameforge:gameforge /app

# ========================================================================
# Stage 4: Application Build
# ========================================================================
FROM secure-gpu AS app-build

WORKDIR /build

# Copy application source code
COPY . .

# Compile Python bytecode for performance
RUN python -m compileall -b . && \
    find . -name "*.py" -delete && \
    find . -name "__pycache__" -exec rm -rf {} + || true

# ========================================================================
# Stage 5: GPU Production Runtime
# ========================================================================
FROM secure-gpu AS gpu-production

# GPU optimization environment variables
ENV GAMEFORGE_ENV=production
ENV LOG_LEVEL=info
ENV SERVICE_TYPE=gpu-workload

# CUDA/GPU specific optimizations
ENV CUDA_LAUNCH_BLOCKING=0
ENV CUDA_CACHE_DISABLE=0
ENV PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:2048,garbage_collection_threshold:0.8,expandable_segments:True"
ENV PYTORCH_JIT=1
ENV PYTORCH_JIT_LOG_LEVEL=ERROR

# Memory and performance optimizations
ENV OMP_NUM_THREADS=8
ENV MKL_NUM_THREADS=8
ENV NCCL_DEBUG=INFO
ENV NCCL_TREE_THRESHOLD=0

# Security environment
ENV PYTHONPATH=/app
ENV HOME=/home/gameforge
ENV PATH="/home/gameforge/.local/bin:$PATH"

WORKDIR /app

# Copy compiled application from build stage
COPY --from=app-build --chown=gameforge:gameforge /build .

# Create GPU workload entrypoint script
RUN echo '#!/bin/bash\n\
set -euo pipefail\n\
\n\
echo "=== GameForge GPU Workload Container Startup ==="\n\
echo "User: $(whoami) (UID: $(id -u), GID: $(id -g))"\n\
echo "Environment: $GAMEFORGE_ENV"\n\
echo "Service Type: $SERVICE_TYPE"\n\
echo "Python Path: $PYTHONPATH"\n\
\n\
# Validate environment\n\
if [ "$GAMEFORGE_ENV" != "production" ]; then\n\
    echo "ERROR: Not in production environment!"\n\
    exit 1\n\
fi\n\
\n\
# GPU Health Check\n\
echo "=== GPU Health Check ==="\n\
if command -v nvidia-smi >/dev/null 2>&1; then\n\
    echo "NVIDIA Driver Status:"\n\
    nvidia-smi --query-gpu=name,memory.total,memory.used,temperature.gpu,utilization.gpu --format=csv,noheader,nounits || echo "GPU query failed"\n\
    echo "CUDA Version: $(nvcc --version | grep release)" || echo "NVCC not available"\n\
else\n\
    echo "ERROR: nvidia-smi not available"\n\
    exit 1\n\
fi\n\
\n\
# Python GPU Check\n\
echo "=== Python GPU Check ==="\n\
python -c "import torch; print(f\"PyTorch Version: {torch.__version__}\"); print(f\"CUDA Available: {torch.cuda.is_available()}\"); print(f\"CUDA Version: {torch.version.cuda}\"); print(f\"GPU Count: {torch.cuda.device_count()}\"); [print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\") for i in range(torch.cuda.device_count())]" || {\n\
    echo "ERROR: GPU not accessible from Python"\n\
    exit 1\n\
}\n\
\n\
# Validate critical directories\n\
for dir in logs cache generated_assets models_cache checkpoints; do\n\
    if [ ! -w "/app/$dir" ]; then\n\
        echo "ERROR: Directory /app/$dir is not writable"\n\
        exit 1\n\
    fi\n\
done\n\
\n\
echo "=== GPU Workload Service Starting ==="\n\
exec "$@"' > /app/entrypoint-gpu.sh && \
    chmod +x /app/entrypoint-gpu.sh && \
    chown gameforge:gameforge /app/entrypoint-gpu.sh

# Security: Switch to non-root user
USER gameforge

# GPU-optimized health check
HEALTHCHECK --interval=60s --timeout=30s --start-period=180s --retries=3 \
    CMD python -c "import torch; exit(0 if torch.cuda.is_available() and torch.cuda.device_count() > 0 else 1)" || exit 1

# Expose application port
EXPOSE 8080

# Security: Set proper entrypoint
ENTRYPOINT ["/app/entrypoint-gpu.sh"]

# Default command - will be overridden by docker-compose
CMD ["python", "-m", "gameforge.gpu.inference_service"]

# Build metadata
ARG BUILD_DATE
ARG VCS_REF
ARG BUILD_VERSION

LABEL \
    org.label-schema.build-date=$BUILD_DATE \
    org.label-schema.vcs-ref=$VCS_REF \
    org.label-schema.vcs-url="https://github.com/Sandmanmmm/ai-game-production-p" \
    org.label-schema.version=$BUILD_VERSION \
    org.label-schema.schema-version="1.0" \
    org.label-schema.name="gameforge-gpu-workload" \
    org.label-schema.description="GameForge GPU-optimized container for AI workloads" \
    maintainer="GameForge Team" \
    gpu.enabled="true" \
    gpu.cuda.version="12.1" \
    gpu.pytorch.version="2.1.0" \
    security.profile="gpu-workload"
