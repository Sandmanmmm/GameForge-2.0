# ========================================================================
# GameForge AI Production Platform - Vast.ai Cloud GPU Deployment
# Complete production-hardened configuration optimized for cloud GPU deployment
# Includes all security, monitoring, and GPU optimization features
# ========================================================================

# ========================================================================
# Security & Resource Templates (Shared Configurations)
# ========================================================================
x-common-env: &common-env
  NODE_ENV: production
  LOG_LEVEL: info
  TZ: UTC
  PYTHONUNBUFFERED: "1"
  PYTHONDONTWRITEBYTECODE: "1"
  PYTHONPATH: "/app"

x-secure-logging: &secure-logging
  driver: "json-file"
  options:
    max-size: "50m"
    max-file: "3"
    compress: "true"
    labels: "environment=production,deployment=vastai"

# Application Security Template
x-app-security: &app-security
  privileged: false
  user: "1001:1001"
  read_only: false  # Apps need some write access
  tmpfs:
    - /tmp:noexec,nosuid,size=1G
    - /var/tmp:noexec,nosuid,size=500m
  security_opt:
    - no-new-privileges:true
    - seccomp=unconfined  # Simplified for cloud deployment
  cap_drop:
    - ALL
  cap_add:
    - CHOWN
    - SETUID
    - SETGID
    - DAC_OVERRIDE

# Database Security Template
x-db-security: &db-security
  privileged: false
  read_only: false
  tmpfs:
    - /tmp:noexec,nosuid,size=200m
    - /var/run:noexec,nosuid,size=100m
  security_opt:
    - no-new-privileges:true
    - seccomp=unconfined
  cap_drop:
    - ALL
  cap_add:
    - CHOWN
    - SETUID
    - SETGID
    - DAC_OVERRIDE

# Web Security Template
x-web-security: &web-security
  privileged: false
  user: "nginx:nginx"
  read_only: true
  tmpfs:
    - /tmp:noexec,nosuid,size=100m
    - /var/cache/nginx:noexec,nosuid,size=200m
    - /var/run:noexec,nosuid,size=50m
  security_opt:
    - no-new-privileges:true
    - seccomp=unconfined
  cap_drop:
    - ALL
  cap_add:
    - CHOWN
    - SETUID
    - SETGID

# Vault Security Template
x-vault-security: &vault-security
  privileged: false
  user: "vault:vault"
  read_only: false
  tmpfs:
    - /tmp:noexec,nosuid,size=100m
  security_opt:
    - no-new-privileges:true
    - seccomp=unconfined
  cap_drop:
    - ALL
  cap_add:
    - IPC_LOCK
    - MLOCK

# GPU Resource Templates
x-gpu-inference-resources: &gpu-inference-resources
  deploy:
    resources:
      limits:
        memory: 16G
        cpus: '4.0'
        pids: 1000
      reservations:
        memory: 8G
        cpus: '2.0'


x-gpu-training-resources: &gpu-training-resources
  deploy:
    resources:
      limits:
        memory: 32G
        cpus: '8.0'
        pids: 2000
      reservations:
        memory: 16G
        cpus: '4.0'


x-web-resources: &web-resources
  deploy:
    resources:
      limits:
        memory: 1G
        cpus: '1.0'
        pids: 200
      reservations:
        memory: 256M
        cpus: '0.2'

x-db-resources: &db-resources
  deploy:
    resources:
      limits:
        memory: 4G
        cpus: '2.0'
        pids: 500
      reservations:
        memory: 1G
        cpus: '0.5'

x-vault-resources: &vault-resources
  deploy:
    resources:
      limits:
        memory: 2G
        cpus: '1.0'
        pids: 200
      reservations:
        memory: 512M
        cpus: '0.2'

services:
  # ========================================================================
  # Security Bootstrap (One-shot initialization)
  # ========================================================================
  security-bootstrap:
    image: alpine:3.18
    container_name: gameforge-security-bootstrap-vastai
    restart: "no"  # One-shot initialization
    privileged: false
    user: "1001:1001"
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100m
    security_opt:
      - no-new-privileges:true
      - seccomp=unconfined
    cap_drop:
      - ALL
    volumes:
      - security-shared:/shared
    environment:
      - SECURITY_MODE=bootstrap
      - LOG_LEVEL=info
      - SECURITY_GATE_THRESHOLD=75
      - BOOTSTRAP_ONLY=true
      - VASTAI_DEPLOYMENT=true
    networks:
      - backend
    logging: *secure-logging
    labels:
      - "security.role=bootstrap"
      - "security.criticality=high"
      - "vastai.deployment=true"
    command: |
      sh -c "
        echo 'Initializing security bootstrap for Vast.ai deployment...'
        mkdir -p /shared/security
        echo 'vastai-deployment' > /shared/security/deployment-type
        echo 'production' > /shared/security/environment
        echo '$(date -Iseconds)' > /shared/security/bootstrap-timestamp
        echo 'Security bootstrap completed successfully'
      "

  # ========================================================================
  # Security Monitor (Continuous monitoring)
  # ========================================================================
  security-monitor:
    image: alpine:3.18
    container_name: gameforge-security-monitor-vastai
    restart: unless-stopped
    <<: *app-security
    volumes:
      - security-shared:/shared:ro
    environment:
      - SECURITY_MODE=monitor
      - LOG_LEVEL=info
      - MONITOR_INTERVAL=300
      - VASTAI_DEPLOYMENT=true
    networks:
      - backend
    logging: *secure-logging
    labels:
      - "security.role=monitoring"
      - "vastai.deployment=true"
    healthcheck:
      test: ["CMD", "sh", "-c", "test -f /shared/security/deployment-type"]
      interval: 60s
      timeout: 10s
      start_period: 30s
      retries: 3
    command: |
      sh -c "
        while true; do
          echo 'Security monitor running at $(date)'
          sleep 300
        done
      "
    depends_on:
      security-bootstrap:
        condition: service_completed_successfully

  # ========================================================================
  # PostgreSQL Database (Production-hardened)
  # ========================================================================
  postgres:
    image: postgres:15.4-alpine
    container_name: gameforge-postgres-vastai
    hostname: postgres
    restart: unless-stopped
    <<: [*db-security, *db-resources]
    user: "999:999"
    environment:
      POSTGRES_DB: gameforge_prod
      POSTGRES_USER: gameforge
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-gameforge_secure_password_2024}
      PGDATA: /var/lib/postgresql/data/pgdata
      POSTGRES_INITDB_ARGS: "--auth-host=scram-sha-256 --auth-local=scram-sha-256"
    volumes:
      - postgres-data:/var/lib/postgresql/data:rw
      - postgres-logs:/var/log/postgresql:rw
    networks:
      - backend
    ports:
      - "127.0.0.1:5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U gameforge -d gameforge_prod"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging: *secure-logging
    labels:
      - "security.profile=database"
      - "vastai.deployment=true"
    command: >
      postgres
      -c shared_preload_libraries=pg_stat_statements
      -c max_connections=200
      -c shared_buffers=1GB
      -c effective_cache_size=3GB
      -c log_statement=mod
      -c log_min_duration_statement=1000

  # ========================================================================
  # Redis Cache (Production-hardened)
  # ========================================================================
  redis:
    image: redis:7.2.1-alpine
    container_name: gameforge-redis-vastai
    hostname: redis
    restart: unless-stopped
    <<: *db-security
    user: "999:999"
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD:-redis_secure_password_2024}
    volumes:
      - redis-data:/data:rw
    networks:
      - backend
    ports:
      - "127.0.0.1:6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging: *secure-logging
    labels:
      - "security.profile=cache"
      - "vastai.deployment=true"
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD:-redis_secure_password_2024}
      --maxmemory 3gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000

  # ========================================================================
  # HashiCorp Vault (Model Security)
  # ========================================================================
  vault:
    image: hashicorp/vault:latest
    container_name: gameforge-vault-vastai
    hostname: vault
    restart: unless-stopped
    <<: [*vault-security, *vault-resources]
    environment:
      VAULT_ADDR: "http://0.0.0.0:8200"
      VAULT_API_ADDR: "http://vault:8200"
      VAULT_DEV_ROOT_TOKEN_ID: ${VAULT_ROOT_TOKEN:-vault_root_token_2024}
      VAULT_DEV_LISTEN_ADDRESS: "0.0.0.0:8200"
      VAULT_LOCAL_CONFIG: |
        {
          "backend": {
            "file": {
              "path": "/vault/data"
            }
          },
          "listener": {
            "tcp": {
              "address": "0.0.0.0:8200",
              "tls_disable": true
            }
          },
          "default_lease_ttl": "168h",
          "max_lease_ttl": "720h",
          "ui": true,
          "log_level": "INFO"
        }
    volumes:
      - vault-data:/vault/data:rw
      - vault-logs:/vault/logs:rw
    networks:
      - backend
      - vault-network
    ports:
      - "127.0.0.1:8200:8200"
    healthcheck:
      test: ["CMD", "vault", "status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging: *secure-logging
    labels:
      - "security.profile=vault"
      - "vastai.deployment=true"
    command: >
      vault server
      -dev-root-token-id=${VAULT_ROOT_TOKEN:-vault_root_token_2024}
      -dev-listen-address=0.0.0.0:8200

  # ========================================================================
  # Elasticsearch (Optimized for Vast.ai)
  # ========================================================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.9.2
    container_name: gameforge-elasticsearch-vastai
    hostname: elasticsearch
    restart: unless-stopped
    user: "1000:1000"
    tmpfs:
      - /tmp:noexec,nosuid,size=200m
    security_opt:
      - no-new-privileges:true
      - seccomp=unconfined
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETUID
      - SETGID
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    environment:
      - node.name=gameforge-elasticsearch-vastai
      - cluster.name=gameforge-vastai-cluster
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms4g -Xmx4g"
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD:-elastic_secure_password_2024}
      - xpack.license.self_generated.type=basic
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data:rw
      - elasticsearch-logs:/usr/share/elasticsearch/logs:rw
    networks:
      - backend
      - monitoring
    ports:
      - "127.0.0.1:9200:9200"
    healthcheck:
      test: ["CMD-SHELL", "curl -u elastic:${ELASTIC_PASSWORD:-elastic_secure_password_2024} -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    logging: *secure-logging
    labels:
      - "security.profile=search-engine"
      - "vastai.deployment=true"
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '1.0'

  # ========================================================================
  # GPU Inference Service - High-Performance AI Workload Processing
  # ========================================================================
  gameforge-gpu-inference:
    build:
      context: .
      dockerfile: Dockerfile.vastai-gpu
      target: production
      args:
        BUILD_DATE: ${BUILD_DATE:-}
        VCS_REF: ${VCS_REF:-}
        BUILD_VERSION: ${BUILD_VERSION:-vastai-v1.0}
        PYTHON_VERSION: "3.10"
        TORCH_VERSION: "2.1.0"
        CUDA_VERSION: "12.1"
    image: gameforge:vastai-gpu-inference
    container_name: gameforge-gpu-inference-vastai
    hostname: gameforge-gpu-inference
    restart: unless-stopped
    runtime: nvidia
    <<: [*app-security, *gpu-inference-resources]
    environment:
      <<: *common-env
      SERVICE_TYPE: gpu-inference
      WORKER_TYPE: gpu-inference
      GPU_MEMORY_FRACTION: "0.7"
      PYTORCH_CUDA_ALLOC_CONF: "max_split_size_mb:1024,garbage_collection_threshold:0.8,expandable_segments:True"
      CUDA_LAUNCH_BLOCKING: "0"
      CUDA_CACHE_DISABLE: "0"
      PYTORCH_JIT: "1"
      NVIDIA_VISIBLE_DEVICES: ${NVIDIA_VISIBLE_DEVICES:-all}
      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
      NVIDIA_REQUIRE_CUDA: "cuda>=12.0"
      MODEL_CACHE_SIZE: "8G"
      BATCH_SIZE: ${INFERENCE_BATCH_SIZE:-4}
      MAX_SEQUENCE_LENGTH: ${MAX_SEQUENCE_LENGTH:-2048}
      # Database connections
      DATABASE_URL: postgresql://gameforge:${POSTGRES_PASSWORD:-gameforge_secure_password_2024}@postgres:5432/gameforge_prod
      REDIS_URL: redis://redis:6379/3
      CELERY_BROKER_URL: redis://redis:6379/4
      CELERY_RESULT_BACKEND: redis://redis:6379/5
      # Vault integration
      VAULT_ADDR: "http://vault:8200"
      VAULT_TOKEN: ${VAULT_TOKEN:-vault_token_2024}
      VAULT_NAMESPACE: "gameforge"
      # Model security
      MODEL_SECURITY_ENABLED: "true"
      SECURITY_SCAN_ENABLED: "true"
      STRICT_MODEL_SECURITY: "true"
      # Vast.ai specific
      VASTAI_DEPLOYMENT: "true"
      VASTAI_INSTANCE_ID: ${VASTAI_INSTANCE_ID:-unknown}
    volumes:
      - gameforge-logs:/app/logs:rw
      - gameforge-cache:/app/cache:rw
      - gameforge-assets:/app/generated_assets:rw
      - model-cache:/app/models_cache:rw
      - gpu-shared-memory:/dev/shm:rw
    networks:
      - backend
      - monitoring
      - gpu-network
    ports:
      - "8081:8080"
    healthcheck:
      test: ["CMD", "python", "-c", "import torch; print(f'GPU available: {torch.cuda.is_available()}'); exit(0 if torch.cuda.is_available() else 1)"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 180s
    logging: *secure-logging
    labels:
      - "security.profile=gpu-worker"
      - "ai.gpu.workload=inference"
      - "vastai.deployment=true"
    command: ["python", "-m", "gameforge.services.gpu_inference_service"]
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      vault:
        condition: service_healthy
      security-monitor:
        condition: service_healthy

  # ========================================================================
  # GPU Training Service - Model Training and Fine-tuning
  # ========================================================================
  gameforge-gpu-training:
    build:
      context: .
      dockerfile: Dockerfile.vastai-gpu
      target: production
      args:
        BUILD_DATE: ${BUILD_DATE:-}
        VCS_REF: ${VCS_REF:-}
        BUILD_VERSION: ${BUILD_VERSION:-vastai-v1.0}
        PYTHON_VERSION: "3.10"
        TORCH_VERSION: "2.1.0"
        CUDA_VERSION: "12.1"
    image: gameforge:vastai-gpu-training
    container_name: gameforge-gpu-training-vastai
    hostname: gameforge-gpu-training
    restart: unless-stopped
    runtime: nvidia
    <<: [*app-security, *gpu-training-resources]
    environment:
      <<: *common-env
      SERVICE_TYPE: gpu-training
      WORKER_TYPE: gpu-training
      GPU_MEMORY_FRACTION: "0.9"
      PYTORCH_CUDA_ALLOC_CONF: "max_split_size_mb:2048,garbage_collection_threshold:0.9,expandable_segments:True"
      CUDA_LAUNCH_BLOCKING: "0"
      CUDA_CACHE_DISABLE: "0"
      PYTORCH_JIT: "1"
      NVIDIA_VISIBLE_DEVICES: ${TRAINING_NVIDIA_VISIBLE_DEVICES:-all}
      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
      NVIDIA_REQUIRE_CUDA: "cuda>=12.0"
      MODEL_CACHE_SIZE: "16G"
      TRAINING_BATCH_SIZE: ${TRAINING_BATCH_SIZE:-8}
      GRADIENT_ACCUMULATION_STEPS: ${GRADIENT_ACCUMULATION_STEPS:-4}
      MIXED_PRECISION: ${MIXED_PRECISION:-fp16}
      # Database connections
      DATABASE_URL: postgresql://gameforge:${POSTGRES_PASSWORD:-gameforge_secure_password_2024}@postgres:5432/gameforge_prod
      REDIS_URL: redis://redis:6379/6
      CELERY_BROKER_URL: redis://redis:6379/7
      CELERY_RESULT_BACKEND: redis://redis:6379/8
      # Vault integration
      VAULT_ADDR: "http://vault:8200"
      VAULT_TOKEN: ${VAULT_TOKEN:-vault_token_2024}
      VAULT_NAMESPACE: "gameforge"
      # Model security
      MODEL_SECURITY_ENABLED: "true"
      SECURITY_SCAN_ENABLED: "true"
      STRICT_MODEL_SECURITY: "true"
      # Vast.ai specific
      VASTAI_DEPLOYMENT: "true"
      VASTAI_INSTANCE_ID: ${VASTAI_INSTANCE_ID:-unknown}
    volumes:
      - gameforge-logs:/app/logs:rw
      - gameforge-cache:/app/cache:rw
      - gameforge-assets:/app/generated_assets:rw
      - model-cache:/app/models_cache:rw
      - training-data:/app/training_data:rw
      - model-checkpoints:/app/checkpoints:rw
      - gpu-shared-memory:/dev/shm:rw
    networks:
      - backend
      - monitoring
      - gpu-network
    ports:
      - "8082:8080"
    healthcheck:
      test: ["CMD", "python", "-c", "import torch; print(f'GPUs available: {torch.cuda.device_count()}'); exit(0 if torch.cuda.device_count() >= 1 else 1)"]
      interval: 120s
      timeout: 60s
      retries: 2
      start_period: 300s
    logging: *secure-logging
    labels:
      - "security.profile=gpu-worker"
      - "ai.gpu.workload=training"
      - "vastai.deployment=true"
    command: ["python", "-m", "gameforge.services.gpu_training_service"]
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      vault:
        condition: service_healthy
      gameforge-gpu-inference:
        condition: service_healthy

  # ========================================================================
  # GameForge Main Application (Optimized for Vast.ai)
  # ========================================================================
  gameforge-app:
    build:
      context: .
      dockerfile: Dockerfile.vastai-gpu
      target: production
      args:
        BUILD_DATE: ${BUILD_DATE:-}
        VCS_REF: ${VCS_REF:-}
        BUILD_VERSION: ${BUILD_VERSION:-vastai-v1.0}
        PYTHON_VERSION: "3.10"
        TORCH_VERSION: "2.1.0"
        CUDA_VERSION: "12.1"
    image: gameforge:vastai-main-app
    container_name: gameforge-app-vastai
    hostname: gameforge-app
    restart: unless-stopped
    runtime: nvidia
    <<: *app-security
    deploy:
      resources:
        limits:
          memory: 12G
          cpus: '6.0'
          pids: 1000
        reservations:
          memory: 4G
          cpus: '2.0'
    environment:
      <<: *common-env
      # Build information
      BUILD_VERSION: ${BUILD_VERSION:-vastai-v1.0}
      VCS_REF: ${VCS_REF:-}
      # Database connections
      DATABASE_URL: postgresql://gameforge:${POSTGRES_PASSWORD:-gameforge_secure_password_2024}@postgres:5432/gameforge_prod
      REDIS_URL: redis://redis:6379/0
      ELASTICSEARCH_URL: http://elasticsearch:9200
      # Security keys
      JWT_SECRET_KEY: ${JWT_SECRET_KEY:-jwt_secret_key_2024}
      SECRET_KEY: ${SECRET_KEY:-app_secret_key_2024}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      # Model Security Configuration
      MODEL_SECURITY_ENABLED: "true"
      SECURITY_SCAN_ENABLED: "true"
      STRICT_MODEL_SECURITY: "true"
      VAULT_HEALTH_CHECK_ENABLED: "true"
      PERFORMANCE_MONITORING_ENABLED: "true"
      # Vault Integration
      VAULT_ADDR: "http://vault:8200"
      VAULT_TOKEN: ${VAULT_TOKEN:-vault_token_2024}
      VAULT_NAMESPACE: "gameforge"
      # GPU optimization environment
      NVIDIA_VISIBLE_DEVICES: ${NVIDIA_VISIBLE_DEVICES:-all}
      NVIDIA_DRIVER_CAPABILITIES: ${NVIDIA_DRIVER_CAPABILITIES:-compute,utility}
      PYTORCH_CUDA_ALLOC_CONF: ${PYTORCH_CUDA_ALLOC_CONF:-max_split_size_mb:512,garbage_collection_threshold:0.6,expandable_segments:True}
      CUDA_LAUNCH_BLOCKING: ${CUDA_LAUNCH_BLOCKING:-0}
      CUDA_CACHE_DISABLE: ${CUDA_CACHE_DISABLE:-0}
      PYTORCH_JIT: ${PYTORCH_JIT:-1}
      # GPU Workload Coordination
      GPU_INFERENCE_ENDPOINT: "http://gameforge-gpu-inference:8080"
      GPU_TRAINING_ENDPOINT: "http://gameforge-gpu-training:8080"
      GPU_WORKLOAD_BALANCER: "round-robin"
      GPU_MEMORY_MONITORING: "true"
      # Performance tuning
      WORKERS: ${WORKERS:-4}
      MAX_WORKERS: ${MAX_WORKERS:-8}
      WORKER_TIMEOUT: ${WORKER_TIMEOUT:-300}
      WORKER_CLASS: ${WORKER_CLASS:-uvicorn.workers.UvicornWorker}
      # Vast.ai specific
      VASTAI_DEPLOYMENT: "true"
      VASTAI_INSTANCE_ID: ${VASTAI_INSTANCE_ID:-unknown}
    volumes:
      - gameforge-logs:/app/logs:rw
      - gameforge-cache:/app/cache:rw
      - gameforge-assets:/app/generated_assets:rw
      - model-cache:/tmp/models:rw
      - monitoring-data:/tmp/monitoring:rw
    networks:
      - frontend
      - backend
      - monitoring
      - vault-network
      - gpu-network
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 120s
    logging: *secure-logging
    labels:
      - "security.profile=main-application"
      - "vastai.deployment=true"
    command: ["python", "-m", "gameforge.main"]
    depends_on:
      security-monitor:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      vault:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy

  # ========================================================================
  # Nginx Reverse Proxy (Optimized for Vast.ai)
  # ========================================================================
  nginx:
    image: nginx:1.24.0-alpine
    container_name: gameforge-nginx-vastai
    hostname: nginx
    restart: unless-stopped
    <<: [*web-security, *web-resources]
    volumes:
      - nginx-logs:/var/log/nginx:rw
      - static-files:/var/www/html:ro
    networks:
      - frontend
    ports:
      - "80:80"
      - "443:443"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging: *secure-logging
    labels:
      - "security.profile=web-server"
      - "vastai.deployment=true"
    depends_on:
      security-monitor:
        condition: service_healthy
      gameforge-app:
        condition: service_healthy
    command: |
      sh -c "
        cat > /etc/nginx/nginx.conf << 'EOF'
        user nginx;
        worker_processes auto;
        error_log /var/log/nginx/error.log warn;
        pid /var/run/nginx.pid;

        events {
            worker_connections 1024;
        }

        http {
            include /etc/nginx/mime.types;
            default_type application/octet-stream;
            
            log_format main '$$remote_addr - $$remote_user [$$time_local] \"$$request\" '
                          '$$status $$body_bytes_sent \"$$http_referer\" '
                          '\"$$http_user_agent\" \"$$http_x_forwarded_for\"';
                          
            access_log /var/log/nginx/access.log main;
            
            sendfile on;
            tcp_nopush on;
            tcp_nodelay on;
            keepalive_timeout 65;
            types_hash_max_size 2048;
            
            server_tokens off;
            
            upstream gameforge_backend {
                server gameforge-app:8080;
            }
            
            upstream gpu_inference {
                server gameforge-gpu-inference:8080;
            }
            
            upstream gpu_training {
                server gameforge-gpu-training:8080;
            }
            
            server {
                listen 80;
                server_name localhost;
                
                location /health {
                    access_log off;
                    return 200 'healthy\n';
                    add_header Content-Type text/plain;
                }
                
                location / {
                    proxy_pass http://gameforge_backend;
                    proxy_set_header Host $$host;
                    proxy_set_header X-Real-IP $$remote_addr;
                    proxy_set_header X-Forwarded-For $$proxy_add_x_forwarded_for;
                    proxy_set_header X-Forwarded-Proto $$scheme;
                }
                
                location /api/gpu/inference/ {
                    proxy_pass http://gpu_inference/;
                    proxy_set_header Host $$host;
                    proxy_set_header X-Real-IP $$remote_addr;
                    proxy_set_header X-Forwarded-For $$proxy_add_x_forwarded_for;
                    proxy_set_header X-Forwarded-Proto $$scheme;
                }
                
                location /api/gpu/training/ {
                    proxy_pass http://gpu_training/;
                    proxy_set_header Host $$host;
                    proxy_set_header X-Real-IP $$remote_addr;
                    proxy_set_header X-Forwarded-For $$proxy_add_x_forwarded_for;
                    proxy_set_header X-Forwarded-Proto $$scheme;
                }
            }
        }
        EOF
        nginx -g 'daemon off;'
      "

  # ========================================================================
  # Background Workers (GPU-enabled)
  # ========================================================================
  gameforge-worker:
    build:
      context: .
      dockerfile: Dockerfile.vastai-gpu
      target: production
    image: gameforge:vastai-worker
    container_name: gameforge-worker-vastai
    hostname: gameforge-worker
    restart: unless-stopped
    runtime: nvidia
    <<: *app-security
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
          pids: 500
        reservations:
          memory: 2G
          cpus: '1.0'
    environment:
      <<: *common-env
      DATABASE_URL: postgresql://gameforge:${POSTGRES_PASSWORD:-gameforge_secure_password_2024}@postgres:5432/gameforge_prod
      REDIS_URL: redis://redis:6379/0
      ELASTICSEARCH_URL: http://elasticsearch:9200
      WORKER_TYPE: background
      CELERY_BROKER_URL: redis://redis:6379/1
      CELERY_RESULT_BACKEND: redis://redis:6379/2
      # GPU optimization
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
      PYTORCH_CUDA_ALLOC_CONF: max_split_size_mb:256,garbage_collection_threshold:0.6,expandable_segments:True
      CUDA_LAUNCH_BLOCKING: 0
      CUDA_CACHE_DISABLE: 0
      PYTORCH_JIT: 1
      # Vast.ai specific
      VASTAI_DEPLOYMENT: "true"
      VASTAI_INSTANCE_ID: ${VASTAI_INSTANCE_ID:-unknown}
    volumes:
      - gameforge-logs:/app/logs:rw
      - gameforge-cache:/app/cache:rw
      - gameforge-assets:/app/generated_assets:rw
      - model-cache:/app/models_cache:rw
    networks:
      - backend
      - monitoring
    healthcheck:
      test: ["CMD", "python", "-c", "import celery; print('Worker healthy')"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 60s
    logging: *secure-logging
    labels:
      - "security.profile=worker"
      - "vastai.deployment=true"
    command: ["celery", "worker", "-A", "gameforge.celery", "--loglevel=info", "--concurrency=4"]
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

  # ========================================================================
  # Prometheus Monitoring (Simplified for Vast.ai)
  # ========================================================================
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: gameforge-prometheus-vastai
    hostname: prometheus
    restart: unless-stopped
    user: "65534:65534"
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100m
    security_opt:
      - no-new-privileges:true
      - seccomp=unconfined
    cap_drop:
      - ALL
    volumes:
      - prometheus-data:/prometheus:rw
    networks:
      - monitoring
    ports:
      - "127.0.0.1:9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging: *secure-logging
    labels:
      - "security.profile=monitoring"
      - "vastai.deployment=true"
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '0.5'

  # ========================================================================
  # Grafana Dashboard (Simplified for Vast.ai)
  # ========================================================================
  grafana:
    image: grafana/grafana:10.1.2
    container_name: gameforge-grafana-vastai
    hostname: grafana
    restart: unless-stopped
    user: "472:472"
    read_only: false
    tmpfs:
      - /tmp:noexec,nosuid,size=100m
    security_opt:
      - no-new-privileges:true
      - seccomp=unconfined
    cap_drop:
      - ALL
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
      GF_SECURITY_SECRET_KEY: ${GRAFANA_SECRET_KEY:-grafana_secret_2024}
      GF_USERS_ALLOW_SIGN_UP: false
      GF_SECURITY_DISABLE_GRAVATAR: true
      GF_ANALYTICS_REPORTING_ENABLED: false
      GF_ANALYTICS_CHECK_FOR_UPDATES: false
      GF_SECURITY_COOKIE_SECURE: false  # HTTP in vast.ai
      GF_SECURITY_COOKIE_SAMESITE: lax
    volumes:
      - grafana-data:/var/lib/grafana:rw
    networks:
      - monitoring
      - frontend
    ports:
      - "127.0.0.1:3000:3000"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging: *secure-logging
    labels:
      - "security.profile=dashboard"
      - "vastai.deployment=true"
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.2'
    depends_on:
      prometheus:
        condition: service_healthy

# ========================================================================
# Network Configuration (Optimized for Vast.ai)
# ========================================================================
networks:
  frontend:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.enable_icc: "false"
      com.docker.network.bridge.enable_ip_masquerade: "true"
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/24
          gateway: 172.20.0.1

  backend:
    driver: bridge
    internal: true
    driver_opts:
      com.docker.network.bridge.enable_icc: "true"
    ipam:
      driver: default
      config:
        - subnet: 172.21.0.0/24
          gateway: 172.21.0.1

  monitoring:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.enable_icc: "true"
    ipam:
      driver: default
      config:
        - subnet: 172.22.0.0/24
          gateway: 172.22.0.1

  vault-network:
    driver: bridge
    internal: true
    driver_opts:
      com.docker.network.bridge.enable_icc: "true"
    ipam:
      driver: default
      config:
        - subnet: 172.23.0.0/24
          gateway: 172.23.0.1

  gpu-network:
    driver: bridge
    internal: true
    driver_opts:
      com.docker.network.bridge.enable_icc: "true"
      com.docker.network.bridge.enable_ip_masquerade: "false"
    ipam:
      driver: default
      config:
        - subnet: 172.25.0.0/24
          gateway: 172.25.0.1

# ========================================================================
# Volume Configuration (Optimized for Vast.ai)
# ========================================================================
volumes:
  # Security infrastructure
  security-shared:
    driver: local
    
  # Application volumes
  gameforge-logs:
    driver: local
  gameforge-cache:
    driver: local
  gameforge-assets:
    driver: local
  
  # Model and GPU volumes
  model-cache:
    driver: local
  gpu-shared-memory:
    driver: tmpfs
    driver_opts:
      type: tmpfs
      device: tmpfs
      o: "size=8G,uid=1001,gid=1001,mode=1777"
  training-data:
    driver: local
  model-checkpoints:
    driver: local
  monitoring-data:
    driver: local
  
  # Infrastructure volumes
  vault-data:
    driver: local
  vault-logs:
    driver: local
  postgres-data:
    driver: local
  postgres-logs:
    driver: local
  redis-data:
    driver: local
  elasticsearch-data:
    driver: local
  elasticsearch-logs:
    driver: local
  nginx-logs:
    driver: local
  static-files:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
