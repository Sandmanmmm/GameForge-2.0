# GameForge Vast.ai GPU Docker Compose Configuration
# ========================================================================
# Optimized for Vast.ai virtual GPU instances with high-performance
# AI workloads, model inference, and training capabilities
# ========================================================================

version: '3.8'

# ========================================================================
# Vast.ai GPU Security Context Templates
# ========================================================================
x-vastai-gpu-security: &vastai-gpu-security
  user: "1001:1001"
  read_only: false  # GPU workloads need write access for model cache
  tmpfs:
    - /tmp:size=8G,mode=1777  # Large tmpfs for GPU operations
    - /app/tmp:noexec,nosuid,size=2G
  security_opt:
    - no-new-privileges:true
  cap_drop:
    - ALL
  cap_add:
    - CHOWN
    - SETUID
    - SETGID
    - FOWNER
    - DAC_OVERRIDE

# ========================================================================
# Vast.ai GPU Resource Templates
# ========================================================================
x-vastai-inference-resources: &vastai-inference-resources
  deploy:
    resources:
      limits:
        memory: 24G  # RTX 4090 optimized
        cpus: '8.0'
        pids: 2000
      reservations:
        memory: 12G
        cpus: '4.0'
    restart_policy:
      condition: on-failure
      delay: 30s
      max_attempts: 3

x-vastai-training-resources: &vastai-training-resources
  deploy:
    resources:
      limits:
        memory: 32G
        cpus: '16.0'
        pids: 4000
      reservations:
        memory: 24G
        cpus: '8.0'
    restart_policy:
      condition: on-failure
      delay: 60s
      max_attempts: 2

# ========================================================================
# Common Vast.ai Environment
# ========================================================================
x-vastai-common-env: &vastai-common-env
  GAMEFORGE_ENV: vastai-production
  LOG_LEVEL: info
  TZ: UTC
  PYTHONPATH: /workspace/app
  # Vast.ai GPU optimizations
  NVIDIA_VISIBLE_DEVICES: all
  NVIDIA_DRIVER_CAPABILITIES: compute,utility
  NVIDIA_REQUIRE_CUDA: "cuda>=12.0"
  CUDA_VISIBLE_DEVICES: "0"
  PYTORCH_CUDA_ALLOC_CONF: "max_split_size_mb:2048,garbage_collection_threshold:0.9,expandable_segments:True"
  CUDA_LAUNCH_BLOCKING: "0"
  CUDA_CACHE_DISABLE: "0"
  PYTORCH_JIT: "1"
  # Vast.ai performance optimizations
  OMP_NUM_THREADS: "8"
  MKL_NUM_THREADS: "8"
  NCCL_DEBUG: "WARN"
  TENSORRT_ENABLED: "true"
  MIXED_PRECISION: "fp16"

x-vastai-logging: &vastai-logging
  driver: "json-file"
  options:
    max-size: "50m"
    max-file: "5"
    compress: "true"
    labels: "service,vastai,gpu"

services:
  # ========================================================================
  # Vast.ai GPU Inference Service - High-Performance AI Inference
  # ========================================================================
  vastai-gpu-inference:
    build:
      context: .
      dockerfile: Dockerfile.vastai-gpu
      target: vastai-production
      args:
        CUDA_VERSION: ${VASTAI_CUDA_VERSION:-12.1}
        PYTORCH_VERSION: ${VASTAI_PYTORCH_VERSION:-2.1.0}
        BUILD_DATE: ${BUILD_DATE:-}
        VCS_REF: ${VCS_REF:-}
    image: gameforge:vastai-inference
    container_name: gameforge-vastai-inference
    hostname: vastai-inference
    restart: unless-stopped
    runtime: nvidia
    <<: [*vastai-gpu-security, *vastai-inference-resources]
    environment:
      <<: *vastai-common-env
      SERVICE_TYPE: vastai-inference
      GPU_MEMORY_FRACTION: ${GPU_MEMORY_FRACTION:-0.8}
      MAX_BATCH_SIZE: ${VASTAI_BATCH_SIZE_INFERENCE:-8}
      MODEL_PRECISION: ${VASTAI_MIXED_PRECISION:-fp16}
      INFERENCE_OPTIMIZATION: "tensorrt"
      DATABASE_URL: postgresql://gameforge:${POSTGRES_PASSWORD:-gameforge123}@vastai-postgres:5432/gameforge_vastai
      REDIS_URL: redis://vastai-redis:6379/0
    volumes:
      - vastai-models:/workspace/models:rw
      - vastai-cache:/workspace/cache:rw
      - vastai-logs:/workspace/logs:rw
      - vastai-shared-memory:/dev/shm:rw
    networks:
      - vastai-gpu-network
      - vastai-backend
    ports:
      - "${VASTAI_API_PORT:-8080}:8080"
      - "8081:8081"  # Inference API
    healthcheck:
      test: ["CMD", "python", "-c", "import torch; exit(0 if torch.cuda.is_available() and torch.cuda.device_count() > 0 else 1)"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 180s
    logging: *vastai-logging
    labels:
      - "vastai.service=inference"
      - "vastai.gpu.enabled=true"
      - "vastai.priority=high"
    command: ["python", "-m", "gameforge.vastai.inference_service"]

  # ========================================================================
  # Vast.ai GPU Training Service - Model Training and Fine-tuning
  # ========================================================================
  vastai-gpu-training:
    build:
      context: .
      dockerfile: Dockerfile.vastai-gpu
      target: vastai-production
      args:
        CUDA_VERSION: ${VASTAI_CUDA_VERSION:-12.1}
        PYTORCH_VERSION: ${VASTAI_PYTORCH_VERSION:-2.1.0}
        BUILD_DATE: ${BUILD_DATE:-}
        VCS_REF: ${VCS_REF:-}
    image: gameforge:vastai-training
    container_name: gameforge-vastai-training
    hostname: vastai-training
    restart: unless-stopped
    runtime: nvidia
    <<: [*vastai-gpu-security, *vastai-training-resources]
    environment:
      <<: *vastai-common-env
      SERVICE_TYPE: vastai-training
      GPU_MEMORY_FRACTION: ${GPU_MEMORY_FRACTION:-0.95}
      TRAINING_BATCH_SIZE: ${VASTAI_BATCH_SIZE_TRAINING:-4}
      GRADIENT_ACCUMULATION_STEPS: "8"
      MIXED_PRECISION: ${VASTAI_MIXED_PRECISION:-fp16}
      TRAINING_OPTIMIZATION: "deepspeed"
      DATABASE_URL: postgresql://gameforge:${POSTGRES_PASSWORD:-gameforge123}@vastai-postgres:5432/gameforge_vastai
      REDIS_URL: redis://vastai-redis:6379/1
      WANDB_PROJECT: "gameforge-vastai"
      MLFLOW_TRACKING_URI: "http://vastai-mlflow:5000"
    volumes:
      - vastai-models:/workspace/models:rw
      - vastai-training-data:/workspace/training_data:rw
      - vastai-checkpoints:/workspace/checkpoints:rw
      - vastai-logs:/workspace/logs:rw
      - vastai-shared-memory:/dev/shm:rw
    networks:
      - vastai-gpu-network
      - vastai-backend
    ports:
      - "8082:8080"  # Training API
    healthcheck:
      test: ["CMD", "python", "-c", "import torch; exit(0 if torch.cuda.is_available() and torch.cuda.device_count() > 0 else 1)"]
      interval: 120s
      timeout: 60s
      retries: 2
      start_period: 300s
    logging: *vastai-logging
    labels:
      - "vastai.service=training"
      - "vastai.gpu.enabled=true"
      - "vastai.priority=highest"
    command: ["python", "-m", "gameforge.vastai.training_service"]
    depends_on:
      vastai-gpu-inference:
        condition: service_healthy

  # ========================================================================
  # Vast.ai Main Application - GPU Coordinator
  # ========================================================================
  vastai-gameforge-app:
    build:
      context: .
      dockerfile: Dockerfile.vastai-gpu
      target: vastai-production
      args:
        CUDA_VERSION: ${VASTAI_CUDA_VERSION:-12.1}
        PYTORCH_VERSION: ${VASTAI_PYTORCH_VERSION:-2.1.0}
    image: gameforge:vastai-app
    container_name: gameforge-vastai-app
    hostname: vastai-app
    restart: unless-stopped
    <<: *vastai-gpu-security
    environment:
      <<: *vastai-common-env
      SERVICE_TYPE: vastai-coordinator
      GPU_INFERENCE_ENDPOINT: "http://vastai-gpu-inference:8080"
      GPU_TRAINING_ENDPOINT: "http://vastai-gpu-training:8080"
      DATABASE_URL: postgresql://gameforge:${POSTGRES_PASSWORD:-gameforge123}@vastai-postgres:5432/gameforge_vastai
      REDIS_URL: redis://vastai-redis:6379/2
      JWT_SECRET_KEY: ${JWT_SECRET_KEY:-vastai-secret-key}
      SECRET_KEY: ${SECRET_KEY:-vastai-app-secret}
    volumes:
      - vastai-logs:/workspace/logs:rw
      - vastai-cache:/workspace/cache:rw
      - vastai-assets:/workspace/assets:rw
    networks:
      - vastai-frontend
      - vastai-backend
      - vastai-gpu-network
    ports:
      - "${VASTAI_API_PORT:-8080}:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 60s
    logging: *vastai-logging
    labels:
      - "vastai.service=app"
      - "vastai.role=coordinator"
    command: ["python", "-m", "gameforge.main"]
    depends_on:
      vastai-postgres:
        condition: service_healthy
      vastai-redis:
        condition: service_healthy

  # ========================================================================
  # Vast.ai PostgreSQL Database
  # ========================================================================
  vastai-postgres:
    image: postgres:15.4-alpine
    container_name: gameforge-vastai-postgres
    hostname: vastai-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: gameforge_vastai
      POSTGRES_USER: gameforge
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-gameforge123}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - vastai-postgres-data:/var/lib/postgresql/data:rw
      - vastai-postgres-logs:/var/log/postgresql:rw
    networks:
      - vastai-backend
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U gameforge -d gameforge_vastai"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging: *vastai-logging
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '0.5'

  # ========================================================================
  # Vast.ai Redis Cache
  # ========================================================================
  vastai-redis:
    image: redis:7.2.1-alpine
    container_name: gameforge-vastai-redis
    hostname: vastai-redis
    restart: unless-stopped
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD:-vastai-redis-pass}
    volumes:
      - vastai-redis-data:/data:rw
    networks:
      - vastai-backend
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging: *vastai-logging
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.1'
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD:-vastai-redis-pass}
      --maxmemory 1gb
      --maxmemory-policy allkeys-lru

  # ========================================================================
  # Vast.ai Monitoring - Grafana Dashboard
  # ========================================================================
  vastai-grafana:
    image: grafana/grafana:10.1.2
    container_name: gameforge-vastai-grafana
    hostname: vastai-grafana
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-vastai-admin}
      GF_USERS_ALLOW_SIGN_UP: false
      GF_SERVER_ROOT_URL: http://localhost:${VASTAI_MONITORING_PORT:-3000}/
    volumes:
      - vastai-grafana-data:/var/lib/grafana:rw
      - ./monitoring/vastai/dashboards:/etc/grafana/provisioning/dashboards:ro
    networks:
      - vastai-frontend
      - vastai-backend
    ports:
      - "${VASTAI_MONITORING_PORT:-3000}:3000"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging: *vastai-logging
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.1'

  # ========================================================================
  # Vast.ai MLflow Tracking Server
  # ========================================================================
  vastai-mlflow:
    image: python:3.10-slim
    container_name: gameforge-vastai-mlflow
    hostname: vastai-mlflow
    restart: unless-stopped
    environment:
      MLFLOW_BACKEND_STORE_URI: postgresql://gameforge:${POSTGRES_PASSWORD:-gameforge123}@vastai-postgres:5432/gameforge_vastai
      MLFLOW_DEFAULT_ARTIFACT_ROOT: /workspace/mlflow/artifacts
    volumes:
      - vastai-mlflow-artifacts:/workspace/mlflow/artifacts:rw
    networks:
      - vastai-backend
    ports:
      - "5000:5000"
    command: >
      sh -c "pip install mlflow psycopg2-binary &&
             mlflow server
             --backend-store-uri postgresql://gameforge:${POSTGRES_PASSWORD:-gameforge123}@vastai-postgres:5432/gameforge_vastai
             --default-artifact-root /workspace/mlflow/artifacts
             --host 0.0.0.0
             --port 5000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging: *vastai-logging
    depends_on:
      vastai-postgres:
        condition: service_healthy

# ========================================================================
# Vast.ai Networks
# ========================================================================
networks:
  vastai-frontend:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.enable_icc: "false"
      com.docker.network.bridge.enable_ip_masquerade: "true"
    ipam:
      driver: default
      config:
        - subnet: 172.30.0.0/24
          gateway: 172.30.0.1

  vastai-backend:
    driver: bridge
    internal: true
    driver_opts:
      com.docker.network.bridge.enable_icc: "true"
    ipam:
      driver: default
      config:
        - subnet: 172.31.0.0/24
          gateway: 172.31.0.1

  vastai-gpu-network:
    driver: bridge
    internal: true
    driver_opts:
      com.docker.network.bridge.enable_icc: "true"
      com.docker.network.bridge.enable_ip_masquerade: "false"
    ipam:
      driver: default
      config:
        - subnet: 172.32.0.0/24
          gateway: 172.32.0.1

# ========================================================================
# Vast.ai Volumes
# ========================================================================
volumes:
  # GPU Workload Volumes
  vastai-models:
    driver: local
    driver_opts:
      type: none
      device: /workspace/models
      o: bind,rw

  vastai-training-data:
    driver: local
    driver_opts:
      type: none
      device: /workspace/training_data
      o: bind,rw

  vastai-checkpoints:
    driver: local
    driver_opts:
      type: none
      device: /workspace/checkpoints
      o: bind,rw

  vastai-cache:
    driver: local

  vastai-logs:
    driver: local

  vastai-assets:
    driver: local

  # Shared Memory Volume for GPU IPC
  vastai-shared-memory:
    driver: tmpfs
    driver_opts:
      type: tmpfs
      device: tmpfs
      o: "size=16G,uid=1001,gid=1001,mode=1777"

  # Database Volumes
  vastai-postgres-data:
    driver: local

  vastai-postgres-logs:
    driver: local

  vastai-redis-data:
    driver: local

  # Monitoring Volumes
  vastai-grafana-data:
    driver: local

  vastai-mlflow-artifacts:
    driver: local
