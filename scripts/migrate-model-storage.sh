#!/bin/bash
# GameForge AI - Model Storage Migration Script
# Migrate 71.63 GB of models to external storage
set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
MODELS_DIR="services/asset-gen/models"
BACKUP_DIR="model-backup"

echo "üöÄ Starting Model Storage Migration"
echo "=" * 50

# Check current model size
if [ -d "$MODELS_DIR" ]; then
    CURRENT_SIZE=$(du -sh "$MODELS_DIR" | cut -f1)
    echo "üìä Current model storage: $CURRENT_SIZE"
else
    echo "‚ùå Models directory not found: $MODELS_DIR"
    exit 1
fi

# Create backup before migration
echo "üíæ Creating backup..."
mkdir -p "$BACKUP_DIR"
if [ ! -d "$BACKUP_DIR/$(date +%Y%m%d)" ]; then
    cp -r "$MODELS_DIR" "$BACKUP_DIR/$(date +%Y%m%d)-models-backup"
    echo "‚úÖ Backup created: $BACKUP_DIR/$(date +%Y%m%d)-models-backup"
fi

# Start MinIO for local testing
echo "üóÑÔ∏è  Starting MinIO storage..."
docker-compose -f docker-compose.model-storage.yml up -d minio
sleep 10

# Wait for MinIO to be ready
echo "‚è≥ Waiting for MinIO to be ready..."
until curl -f http://localhost:9000/minio/health/live > /dev/null 2>&1; do
    sleep 2
done
echo "‚úÖ MinIO is ready"

# Upload models to MinIO
echo "üì§ Uploading models to external storage..."
python scripts/model-management/model-uploader.py \
    stable-diffusion-xl-base-1.0 \
    "$MODELS_DIR/stable-diffusion-xl-base-1.0" \
    --backend minio \
    --format safetensors fp16.safetensors

# Verify upload
echo "üîç Verifying upload..."
python scripts/model-management/model-uploader.py stable-diffusion-xl-base-1.0 --verify

# Test download
echo "üì• Testing model download..."
rm -rf /tmp/test-download
python scripts/model-management/model-downloader.py stable-diffusion-xl-base-1.0 --format safetensors fp16.safetensors

if [ -d "/tmp/model-cache/stable-diffusion-xl-base-1.0" ]; then
    echo "‚úÖ Download test successful"
    
    # Calculate space savings
    ORIGINAL_SIZE=$(du -s "$MODELS_DIR" | cut -f1)
    NEW_SIZE=$(du -s "/tmp/model-cache/stable-diffusion-xl-base-1.0" | cut -f1)
    SAVINGS=$((ORIGINAL_SIZE - NEW_SIZE))
    SAVINGS_GB=$((SAVINGS / 1024 / 1024))
    
    echo ""
    echo "üí∞ SPACE SAVINGS ANALYSIS"
    echo "========================"
    echo "Original size: $ORIGINAL_SIZE KB"
    echo "Optimized size: $NEW_SIZE KB"
    echo "Space saved: $SAVINGS KB (~$SAVINGS_GB GB)"
    echo ""
    
    # Prompt for local model removal
    read -p "üóëÔ∏è  Remove local models to save space? (y/N): " REMOVE_LOCAL
    if [[ $REMOVE_LOCAL =~ ^[Yy]$ ]]; then
        echo "üßπ Removing local models..."
        mv "$MODELS_DIR" "$BACKUP_DIR/$(date +%Y%m%d)-models-removed"
        mkdir -p "$MODELS_DIR"
        
        # Create placeholder
        cat > "$MODELS_DIR/README.md" << EOF
# GameForge AI Models - External Storage

Models have been migrated to external storage for space optimization.

## Usage

Models are automatically downloaded on-demand using:
```bash
python scripts/model-management/model-downloader.py <model-name>
```

## Available Models

- stable-diffusion-xl-base-1.0 (Text-to-Image)

## Storage Backends

- MinIO (Local): http://localhost:9000
- S3 (Production): s3://gameforge-ai-models

## Configuration

See \`config/models/model-registry.json\` for full configuration.
EOF
        
        echo "‚úÖ Local models removed, saved ~$SAVINGS_GB GB"
        echo "üìù Created README with usage instructions"
    fi
else
    echo "‚ùå Download test failed"
    exit 1
fi

echo ""
echo "üéâ Model Storage Migration Complete!"
echo "====================================="
echo "‚Ä¢ Models uploaded to external storage"
echo "‚Ä¢ On-demand downloading configured"
echo "‚Ä¢ Docker integration ready"
echo "‚Ä¢ Space savings: ~$SAVINGS_GB GB"
echo ""
echo "Next steps:"
echo "1. Test application with: docker-compose -f docker-compose.model-storage.yml up"
echo "2. Set PRELOAD_MODELS=true for production deployment"
echo "3. Configure S3 credentials for production storage"
