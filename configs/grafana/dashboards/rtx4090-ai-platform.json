{
  "dashboard": {
    "id": null,
    "title": "GameForge RTX 4090 AI Platform",
    "tags": ["gameforge", "ai", "rtx4090", "gpu"],
    "style": "dark",
    "timezone": "browser",
    "editable": true,
    "hideControls": false,
    "graphTooltip": 1,
    "panels": [
      {
        "id": 1,
        "title": "RTX 4090 GPU Utilization",
        "type": "stat",
        "targets": [
          {
            "expr": "DCGM_FI_DEV_GPU_UTIL",
            "format": "time_series",
            "legendFormat": "GPU Utilization"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": 0,
            "max": 100,
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 70},
                {"color": "red", "value": 90}
              ]
            }
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "RTX 4090 Memory Usage",
        "type": "stat",
        "targets": [
          {
            "expr": "DCGM_FI_DEV_FB_USED / DCGM_FI_DEV_FB_TOTAL * 100",
            "format": "time_series",
            "legendFormat": "Memory Usage"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": 0,
            "max": 100,
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 70},
                {"color": "red", "value": 85}
              ]
            }
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 6, "y": 0}
      },
      {
        "id": 3,
        "title": "RTX 4090 Temperature",
        "type": "gauge",
        "targets": [
          {
            "expr": "DCGM_FI_DEV_GPU_TEMP",
            "format": "time_series",
            "legendFormat": "GPU Temperature"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "celsius",
            "min": 20,
            "max": 90,
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 70},
                {"color": "red", "value": 80}
              ]
            }
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 12, "y": 0}
      },
      {
        "id": 4,
        "title": "RTX 4090 Power Draw",
        "type": "stat",
        "targets": [
          {
            "expr": "DCGM_FI_DEV_POWER_USAGE",
            "format": "time_series",
            "legendFormat": "Power Draw"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "watt",
            "min": 0,
            "max": 450,
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 350},
                {"color": "red", "value": 400}
              ]
            }
          }
        },
        "gridPos": {"h": 8, "w": 6, "x": 18, "y": 0}
      },
      {
        "id": 5,
        "title": "TorchServe Model Performance",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(torchserve_inference_requests_total[5m])",
            "format": "time_series",
            "legendFormat": "Requests/sec - {{model_name}}"
          },
          {
            "expr": "histogram_quantile(0.95, rate(torchserve_inference_latency_microseconds_bucket[5m]))",
            "format": "time_series",
            "legendFormat": "95th Percentile Latency - {{model_name}}"
          }
        ],
        "yAxes": [
          {"label": "Requests/sec", "min": 0},
          {"label": "Latency (Î¼s)", "min": 0}
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
      },
      {
        "id": 6,
        "title": "Ray Cluster Status",
        "type": "table",
        "targets": [
          {
            "expr": "ray_cluster_active_nodes",
            "format": "table",
            "legendFormat": "Active Nodes"
          },
          {
            "expr": "ray_cluster_total_cpus",
            "format": "table", 
            "legendFormat": "Total CPUs"
          },
          {
            "expr": "ray_cluster_total_memory_gb",
            "format": "table",
            "legendFormat": "Total Memory (GB)"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
      },
      {
        "id": 7,
        "title": "Memory Usage Over Time",
        "type": "graph",
        "targets": [
          {
            "expr": "DCGM_FI_DEV_FB_USED / 1024 / 1024",
            "format": "time_series",
            "legendFormat": "GPU Memory Used (GB)"
          },
          {
            "expr": "container_memory_usage_bytes{container_name=~\"torchserve.*\"} / 1024 / 1024 / 1024",
            "format": "time_series",
            "legendFormat": "TorchServe Memory (GB)"
          },
          {
            "expr": "container_memory_usage_bytes{container_name=~\"ray.*\"} / 1024 / 1024 / 1024",
            "format": "time_series",
            "legendFormat": "Ray Memory (GB)"
          }
        ],
        "yAxes": [
          {"label": "Memory (GB)", "min": 0}
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 16}
      },
      {
        "id": 8,
        "title": "AI Model Inference Metrics",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(torchserve_inference_requests_total{model_name=\"stable-diffusion-xl\"}[5m])",
            "format": "time_series",
            "legendFormat": "Stable Diffusion XL - Req/s"
          },
          {
            "expr": "rate(torchserve_inference_requests_total{model_name=\"llama-7b-chat\"}[5m])",
            "format": "time_series",
            "legendFormat": "Llama 7B Chat - Req/s"
          },
          {
            "expr": "rate(torchserve_inference_requests_total{model_name=\"whisper-large\"}[5m])",
            "format": "time_series",
            "legendFormat": "Whisper Large - Req/s"
          }
        ],
        "yAxes": [
          {"label": "Requests/sec", "min": 0}
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 24}
      },
      {
        "id": 9,
        "title": "System Resources",
        "type": "graph",
        "targets": [
          {
            "expr": "100 - (avg by (instance) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "format": "time_series",
            "legendFormat": "CPU Usage %"
          },
          {
            "expr": "(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100",
            "format": "time_series",
            "legendFormat": "Memory Usage %"
          },
          {
            "expr": "100 - ((node_filesystem_avail_bytes{mountpoint=\"/\"} / node_filesystem_size_bytes{mountpoint=\"/\"}) * 100)",
            "format": "time_series",
            "legendFormat": "Disk Usage %"
          }
        ],
        "yAxes": [
          {"label": "Usage %", "min": 0, "max": 100}
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 24}
      },
      {
        "id": 10,
        "title": "Container Health Status",
        "type": "table",
        "targets": [
          {
            "expr": "up{job=~\"torchserve|ray-head|ray-worker|prometheus|grafana\"}",
            "format": "table",
            "legendFormat": "{{job}} - {{instance}}"
          }
        ],
        "transformations": [
          {
            "id": "organize",
            "options": {
              "excludeByName": {"Time": true},
              "renameByName": {
                "job": "Service",
                "instance": "Instance",
                "Value": "Status"
              }
            }
          }
        ],
        "fieldConfig": {
          "overrides": [
            {
              "matcher": {"id": "byName", "options": "Status"},
              "properties": [
                {
                  "id": "mappings",
                  "value": [
                    {"options": {"0": {"text": "Down", "color": "red"}}, "type": "value"},
                    {"options": {"1": {"text": "Up", "color": "green"}}, "type": "value"}
                  ]
                }
              ]
            }
          ]
        },
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 32}
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "timepicker": {
      "refresh_intervals": ["5s", "10s", "30s", "1m", "5m", "15m", "30m", "1h", "2h", "1d"]
    },
    "refresh": "30s"
  }
}
