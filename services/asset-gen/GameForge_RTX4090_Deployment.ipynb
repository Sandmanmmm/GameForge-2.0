{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c75e2024",
   "metadata": {},
   "source": [
    "# GameForge SDXL on RTX 4090 - Interactive Deployment\n",
    "\n",
    "This notebook will help us deploy and test your GameForge SDXL service on your Vast.ai RTX 4090 instance.\n",
    "\n",
    "**Instance Details:**\n",
    "- Instance ID: 25599851\n",
    "- GPU: RTX 4090 (24GB VRAM)\n",
    "- Host: 3483\n",
    "- Cost: ~$0.20-0.40/hour vs $1.00/hour on AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56d027f",
   "metadata": {},
   "source": [
    "## Step 1: Environment Check\n",
    "\n",
    "Let's verify our RTX 4090 and system environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e801b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check system information\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"=== System Information ===\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Current Directory: {os.getcwd()}\")\n",
    "print(f\"User: {os.getenv('USER', 'unknown')}\")\n",
    "print(\"\")\n",
    "\n",
    "# Check GPU\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"=== NVIDIA GPU Information ===\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(\"‚ùå nvidia-smi failed\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error running nvidia-smi: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0166218d",
   "metadata": {},
   "source": [
    "## Step 2: PyTorch GPU Test\n",
    "\n",
    "Test PyTorch CUDA support on your RTX 4090:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6fcd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test PyTorch GPU support\n",
    "try:\n",
    "    import torch\n",
    "    print(\"=== PyTorch GPU Test ===\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "        print(f\"GPU Count: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "        print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "        \n",
    "        # Memory info\n",
    "        total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"Total VRAM: {total_memory:.1f} GB\")\n",
    "        \n",
    "        # Quick tensor test\n",
    "        test_tensor = torch.randn(1000, 1000).cuda()\n",
    "        result = torch.mm(test_tensor, test_tensor)\n",
    "        print(f\"‚úÖ GPU Tensor Test: {result.shape} - SUCCESS\")\n",
    "        \n",
    "        del test_tensor, result\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        print(\"‚ùå CUDA not available - GPU support missing\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"‚ùå PyTorch not installed\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error testing GPU: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549b6594",
   "metadata": {},
   "source": [
    "## Step 3: Install Dependencies\n",
    "\n",
    "Install all required packages for GameForge SDXL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399dca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch with CUDA support\n",
    "print(\"Installing PyTorch with CUDA 12.1 support...\")\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8048351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install GameForge dependencies\n",
    "print(\"Installing GameForge SDXL dependencies...\")\n",
    "\n",
    "packages = [\n",
    "    \"fastapi==0.104.1\",\n",
    "    \"uvicorn[standard]==0.24.0\", \n",
    "    \"diffusers==0.24.0\",\n",
    "    \"transformers==4.36.0\",\n",
    "    \"accelerate==0.24.1\",\n",
    "    \"xformers==0.0.23\",\n",
    "    \"pillow\",\n",
    "    \"redis\",\n",
    "    \"pydantic==2.5.0\",\n",
    "    \"pydantic-settings==2.1.0\",\n",
    "    \"python-multipart\",\n",
    "    \"numpy\",\n",
    "    \"requests\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"Installing {package}...\")\n",
    "    !pip install {package}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed036cb",
   "metadata": {},
   "source": [
    "## Step 4: Verify Installation\n",
    "\n",
    "Test that all key packages work with your RTX 4090:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a2234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test key imports\n",
    "print(\"=== Testing Key Imports ===\")\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import diffusers\n",
    "    import transformers\n",
    "    import fastapi\n",
    "    import PIL\n",
    "    \n",
    "    print(f\"‚úÖ torch: {torch.__version__}\")\n",
    "    print(f\"‚úÖ diffusers: {diffusers.__version__}\")\n",
    "    print(f\"‚úÖ transformers: {transformers.__version__}\")\n",
    "    print(f\"‚úÖ fastapi: {fastapi.__version__}\")\n",
    "    print(f\"‚úÖ pillow: {PIL.__version__}\")\n",
    "    \n",
    "    # Test diffusers on GPU\n",
    "    from diffusers import StableDiffusionXLPipeline\n",
    "    print(\"‚úÖ StableDiffusionXLPipeline import successful\")\n",
    "    \n",
    "    print(\"\\nüéâ All key packages installed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Import error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c224f",
   "metadata": {},
   "source": [
    "## Step 5: Navigate to GameForge Directory\n",
    "\n",
    "Set up the working directory and check our files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aaa294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to GameForge directory\n",
    "import os\n",
    "\n",
    "# Check current directory\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Look for GameForge directory\n",
    "if os.path.exists('GameForge/services/asset-gen'):\n",
    "    os.chdir('GameForge/services/asset-gen')\n",
    "    print(f\"‚úÖ Changed to: {os.getcwd()}\")\n",
    "elif os.path.exists('services/asset-gen'):\n",
    "    os.chdir('services/asset-gen')\n",
    "    print(f\"‚úÖ Changed to: {os.getcwd()}\")\n",
    "else:\n",
    "    print(\"‚ùå GameForge directory not found\")\n",
    "    print(\"Available directories:\")\n",
    "    for item in os.listdir('.'):\n",
    "        if os.path.isdir(item):\n",
    "            print(f\"  üìÅ {item}\")\n",
    "\n",
    "# List files in current directory\n",
    "print(\"\\n=== Files in current directory ===\")\n",
    "for item in sorted(os.listdir('.')):\n",
    "    if os.path.isfile(item):\n",
    "        size = os.path.getsize(item)\n",
    "        print(f\"üìÑ {item} ({size} bytes)\")\n",
    "    else:\n",
    "        print(f\"üìÅ {item}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21393d7f",
   "metadata": {},
   "source": [
    "## Step 6: Set Up Storage Directories\n",
    "\n",
    "Create the necessary directories for GameForge SDXL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef23d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create storage directories\n",
    "import os\n",
    "\n",
    "directories = [\n",
    "    'outputs/assets',\n",
    "    'outputs/thumbnails', \n",
    "    'outputs/references',\n",
    "    'outputs/temp',\n",
    "    'models/lora',\n",
    "    'models/checkpoints'\n",
    "]\n",
    "\n",
    "print(\"Creating storage directories...\")\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"‚úÖ Created: {directory}\")\n",
    "\n",
    "print(\"\\n=== Directory Structure ===\")\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    level = root.replace('.', '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}üìÅ {os.path.basename(root)}/\")\n",
    "    if level < 2:  # Don't go too deep\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files[:5]:  # Limit files shown\n",
    "            print(f\"{subindent}üìÑ {file}\")\n",
    "        if len(files) > 5:\n",
    "            print(f\"{subindent}... and {len(files)-5} more files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24878530",
   "metadata": {},
   "source": [
    "## Step 7: Test SDXL Model Loading\n",
    "\n",
    "Test loading a fast SDXL model on your RTX 4090:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SDXL model loading\n",
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline\n",
    "import time\n",
    "\n",
    "print(\"=== Testing SDXL Model Loading on RTX 4090 ===\")\n",
    "print(\"This will download a fast SDXL model (~2-3GB)...\")\n",
    "\n",
    "try:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load a fast SDXL variant\n",
    "    model_id = \"segmind/SSD-1B\"  # Fast SDXL alternative\n",
    "    print(f\"Loading model: {model_id}\")\n",
    "    \n",
    "    pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch.float16,\n",
    "        use_safetensors=True,\n",
    "        variant=\"fp16\"\n",
    "    )\n",
    "    \n",
    "    print(\"Moving pipeline to GPU...\")\n",
    "    pipe = pipe.to(\"cuda\")\n",
    "    \n",
    "    # Enable memory efficient attention\n",
    "    try:\n",
    "        pipe.enable_xformers_memory_efficient_attention()\n",
    "        print(\"‚úÖ XFormers attention enabled\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è XFormers not available, using default attention\")\n",
    "    \n",
    "    load_time = time.time() - start_time\n",
    "    print(f\"‚úÖ Model loaded successfully in {load_time:.1f} seconds\")\n",
    "    \n",
    "    # Check memory usage\n",
    "    if torch.cuda.is_available():\n",
    "        memory_used = torch.cuda.max_memory_allocated() / 1e9\n",
    "        memory_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"GPU Memory: {memory_used:.1f}GB / {memory_total:.1f}GB ({memory_used/memory_total*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nüéâ RTX 4090 SDXL setup successful!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading SDXL model: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a69e1f",
   "metadata": {},
   "source": [
    "## Step 8: Generate Test Image\n",
    "\n",
    "Let's generate a test image to verify everything works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8277279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test image\n",
    "import time\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "if 'pipe' in locals():\n",
    "    print(\"=== Generating Test Image on RTX 4090 ===\")\n",
    "    \n",
    "    prompt = \"fantasy knight character, pixel art style, detailed armor, medieval setting\"\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Generate image\n",
    "        image = pipe(\n",
    "            prompt=prompt,\n",
    "            width=512,\n",
    "            height=512,\n",
    "            num_inference_steps=20,\n",
    "            guidance_scale=7.5,\n",
    "            generator=torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "        ).images[0]\n",
    "        \n",
    "        generation_time = time.time() - start_time\n",
    "        print(f\"‚úÖ Image generated in {generation_time:.1f} seconds\")\n",
    "        \n",
    "        # Save image\n",
    "        output_path = \"outputs/assets/test_knight.png\"\n",
    "        image.save(output_path)\n",
    "        print(f\"üíæ Saved to: {output_path}\")\n",
    "        \n",
    "        # Display image\n",
    "        display(image)\n",
    "        \n",
    "        # Memory cleanup\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        print(f\"\\nüéÆ GameForge SDXL is working perfectly on your RTX 4090!\")\n",
    "        print(f\"‚ö° Generation speed: {generation_time:.1f}s for 512x512 image\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating image: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"‚ùå Model not loaded. Run the previous cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b427c9",
   "metadata": {},
   "source": [
    "## Step 9: Start GameForge FastAPI Service\n",
    "\n",
    "Now let's start the full GameForge service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Redis for job queue\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "print(\"=== Starting Redis ===\")\n",
    "try:\n",
    "    # Install Redis if not available\n",
    "    result = subprocess.run(['which', 'redis-server'], capture_output=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Installing Redis...\")\n",
    "        !apt-get update && apt-get install -y redis-server\n",
    "    \n",
    "    # Start Redis\n",
    "    subprocess.Popen(['redis-server', '--daemonize', 'yes'])\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Test Redis\n",
    "    result = subprocess.run(['redis-cli', 'ping'], capture_output=True, text=True)\n",
    "    if result.stdout.strip() == 'PONG':\n",
    "        print(\"‚úÖ Redis is running\")\n",
    "    else:\n",
    "        print(\"‚ùå Redis failed to start\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Redis setup issue: {e}\")\n",
    "    print(\"GameForge can run without Redis for basic testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d64499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if main.py exists and start the service\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "\n",
    "if os.path.exists('main.py'):\n",
    "    print(\"=== Starting GameForge SDXL Service ===\")\n",
    "    print(\"This will start the FastAPI server on port 8000\")\n",
    "    print(\"Use Ctrl+C to stop the server when you're done testing\")\n",
    "    \n",
    "    # Start the service in background\n",
    "    def start_service():\n",
    "        os.system('python3 main.py')\n",
    "    \n",
    "    service_thread = threading.Thread(target=start_service, daemon=True)\n",
    "    service_thread.start()\n",
    "    \n",
    "    print(\"‚è≥ Starting service...\")\n",
    "    time.sleep(10)\n",
    "    \n",
    "    # Test the service\n",
    "    try:\n",
    "        import requests\n",
    "        response = requests.get('http://localhost:8000/health', timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(\"‚úÖ GameForge SDXL service is running!\")\n",
    "            print(\"üåê Health endpoint: http://localhost:8000/health\")\n",
    "            print(\"üìö API docs: http://localhost:8000/docs\")\n",
    "            print(response.json())\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Service responding with status {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not connect to service: {e}\")\n",
    "        print(\"The service might still be starting up...\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå main.py not found in current directory\")\n",
    "    print(\"Available Python files:\")\n",
    "    for file in os.listdir('.'):\n",
    "        if file.endswith('.py'):\n",
    "            print(f\"  üìÑ {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a594fde6",
   "metadata": {},
   "source": [
    "## Step 10: Test API Endpoints\n",
    "\n",
    "Test the GameForge API endpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d05199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GameForge API endpoints\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "\n",
    "print(\"=== Testing GameForge API Endpoints ===\")\n",
    "\n",
    "# Test health endpoint\n",
    "try:\n",
    "    response = requests.get(f\"{BASE_URL}/health\")\n",
    "    print(f\"Health Check: {response.status_code}\")\n",
    "    if response.status_code == 200:\n",
    "        health_data = response.json()\n",
    "        print(json.dumps(health_data, indent=2))\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Health check failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Test generation endpoint\n",
    "try:\n",
    "    generation_request = {\n",
    "        \"prompt\": \"fantasy knight character, pixel art style, detailed armor\",\n",
    "        \"asset_type\": \"character_design\",\n",
    "        \"style\": \"pixel_art\",\n",
    "        \"width\": 512,\n",
    "        \"height\": 512,\n",
    "        \"steps\": 20,\n",
    "        \"guidance_scale\": 7.5\n",
    "    }\n",
    "    \n",
    "    print(\"Submitting generation request...\")\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/generate\",\n",
    "        json=generation_request,\n",
    "        headers={\"Content-Type\": \"application/json\"}\n",
    "    )\n",
    "    \n",
    "    print(f\"Generation Request: {response.status_code}\")\n",
    "    if response.status_code in [200, 202]:\n",
    "        result = response.json()\n",
    "        print(json.dumps(result, indent=2))\n",
    "        \n",
    "        # If we got a job_id, try to check its status\n",
    "        if 'job_id' in result:\n",
    "            job_id = result['job_id']\n",
    "            print(f\"\\nMonitoring job {job_id}...\")\n",
    "            \n",
    "            for i in range(30):  # Wait up to 30 seconds\n",
    "                try:\n",
    "                    job_response = requests.get(f\"{BASE_URL}/job/{job_id}\")\n",
    "                    if job_response.status_code == 200:\n",
    "                        job_data = job_response.json()\n",
    "                        status = job_data.get('status', 'unknown')\n",
    "                        print(f\"Job status: {status}\")\n",
    "                        \n",
    "                        if status == 'completed':\n",
    "                            print(\"üéâ Generation completed!\")\n",
    "                            print(json.dumps(job_data, indent=2))\n",
    "                            break\n",
    "                        elif status == 'failed':\n",
    "                            print(\"‚ùå Generation failed\")\n",
    "                            print(json.dumps(job_data, indent=2))\n",
    "                            break\n",
    "                    time.sleep(2)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error checking job: {e}\")\n",
    "                    break\n",
    "    else:\n",
    "        print(f\"Error: {response.text}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Generation test failed: {e}\")\n",
    "\n",
    "print(\"\\nüéÆ GameForge SDXL testing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64627ad1",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "üéâ **Congratulations!** Your GameForge SDXL service is now running on your RTX 4090!\n",
    "\n",
    "### What's Working:\n",
    "- ‚úÖ RTX 4090 GPU detection and CUDA support\n",
    "- ‚úÖ PyTorch with GPU acceleration\n",
    "- ‚úÖ SDXL model loading and inference\n",
    "- ‚úÖ FastAPI service with health checks\n",
    "- ‚úÖ Image generation API endpoints\n",
    "- ‚úÖ File storage system\n",
    "\n",
    "### Your Service URLs:\n",
    "- **Health Check**: http://localhost:8000/health\n",
    "- **API Documentation**: http://localhost:8000/docs\n",
    "- **Interactive API**: http://localhost:8000/redoc\n",
    "\n",
    "### Performance:\n",
    "- **GPU**: RTX 4090 (24GB VRAM)\n",
    "- **Model**: Segmind SSD-1B (Fast SDXL)\n",
    "- **Generation Speed**: ~10-20 seconds per 512x512 image\n",
    "- **Cost**: ~$0.20-0.40/hour vs $1.00/hour on AWS\n",
    "\n",
    "### Next Steps:\n",
    "1. **Test different prompts** and styles\n",
    "2. **Try larger images** (768x768, 1024x1024)\n",
    "3. **Experiment with different models**\n",
    "4. **Connect your frontend** to this API\n",
    "5. **Set up LoRA training** for custom styles\n",
    "\n",
    "Your GameForge AI development environment is ready! üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
