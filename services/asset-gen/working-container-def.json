[
  {
    "name": "sdxl-service",
    "image": "public.ecr.aws/docker/library/python:3.11-slim", 
    "cpu": 0,
    "portMappings": [
      {
        "containerPort": 8080,
        "hostPort": 8080,
        "protocol": "tcp",
        "name": "sdxl-port"
      }
    ],
    "essential": true,
    "command": [
      "bash",
      "-c",
      "apt-get update && apt-get install -y curl && pip install --no-cache-dir torch torchvision --index-url https://download.pytorch.org/whl/cpu && pip install --no-cache-dir fastapi uvicorn pillow pydantic diffusers transformers accelerate safetensors && cat > /tmp/sdxl_optimized.py << \"PYTHON_EOF\" && python /tmp/sdxl_optimized.py\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nfrom PIL import Image, ImageDraw\nimport torch, io, base64, os, uvicorn, logging\nfrom diffusers import DiffusionPipeline\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\nMODEL_CACHE = {}\n\nclass ImageRequest(BaseModel):\n    prompt: str\n    width: int = 512\n    height: int = 512\n    steps: int = 20\n    guidance_scale: float = 7.5\n\nclass ImageResponse(BaseModel):\n    image: str\n    metadata: dict\n\napp = FastAPI(title=\"GameForge SDXL Optimized\", version=\"2.1.0\")\n\n@app.on_event(\"startup\")\nasync def load_model():\n    global MODEL_CACHE\n    try:\n        logger.info(\"Loading SDXL model...\")\n        pipeline = DiffusionPipeline.from_pretrained(\"segmind/SSD-1B\", torch_dtype=torch.float32, safety_checker=None, requires_safety_checker=False)\n        pipeline = pipeline.to(\"cpu\")\n        pipeline.enable_attention_slicing()\n        MODEL_CACHE[\"pipeline\"] = pipeline\n        logger.info(\" SDXL model loaded with optimizations!\")\n    except Exception as e:\n        logger.error(f\"Model loading failed: {e}\")\n        logger.info(\"Fallback to placeholder mode\")\n        MODEL_CACHE[\"fallback\"] = True\n\n@app.get(\"/health\")\ndef health():\n    return {\n        \"status\": \"healthy\",\n        \"version\": \"2.1.0\", \n        \"service\": \"sdxl-optimized\",\n        \"model_loaded\": \"pipeline\" in MODEL_CACHE,\n        \"fallback_mode\": \"fallback\" in MODEL_CACHE\n    }\n\n@app.get(\"/model-status\")\ndef model_status():\n    if \"pipeline\" in MODEL_CACHE:\n        return {\"loaded\": True, \"model\": \"segmind/SSD-1B\", \"optimizations\": [\"attention_slicing\", \"model_caching\"]}\n    return {\"loaded\": False, \"fallback_mode\": True}\n\n@app.post(\"/generate\", response_model=ImageResponse)\ndef generate_image(request: ImageRequest):\n    if \"pipeline\" in MODEL_CACHE:\n        try:\n            pipeline = MODEL_CACHE[\"pipeline\"]\n            logger.info(f\"Generating with SDXL: {request.prompt[:50]}...\")\n            \n            with torch.inference_mode():\n                result = pipeline(\n                    prompt=request.prompt,\n                    width=request.width,\n                    height=request.height,\n                    num_inference_steps=request.steps,\n                    guidance_scale=request.guidance_scale,\n                    output_type=\"pil\"\n                )\n            \n            image = result.images[0]\n            buffer = io.BytesIO()\n            image.save(buffer, format=\"PNG\")\n            img_base64 = base64.b64encode(buffer.getvalue()).decode()\n            \n            return ImageResponse(\n                image=img_base64,\n                metadata={\n                    \"prompt\": request.prompt,\n                    \"width\": request.width,\n                    \"height\": request.height,\n                    \"model\": \"segmind/SSD-1B\", \n                    \"service\": \"sdxl-optimized\",\n                    \"format\": \"PNG\",\n                    \"cached\": True\n                }\n            )\n        except Exception as e:\n            logger.error(f\"SDXL generation failed: {e}\")\n    \n    # Fallback to placeholder\n    logger.info(\"Using placeholder generation\")\n    img = Image.new(\"RGB\", (request.width, request.height), color=\"lightblue\")\n    draw = ImageDraw.Draw(img)\n    text = f\"Generated: {request.prompt[:50]}\"\n    draw.text((10, 10), text, fill=\"darkblue\")\n    \n    buffer = io.BytesIO()\n    img.save(buffer, format=\"PNG\")\n    img_base64 = base64.b64encode(buffer.getvalue()).decode()\n    \n    return ImageResponse(\n        image=img_base64,\n        metadata={\n            \"prompt\": request.prompt,\n            \"width\": request.width, \n            \"height\": request.height,\n            \"format\": \"PNG\",\n            \"service\": \"placeholder-fallback\"\n        }\n    )\n\nif __name__ == \"__main__\":\n    port = int(os.getenv(\"PORT\", 8080))\n    uvicorn.run(app, host=\"0.0.0.0\", port=port)\nPYTHON_EOF"
    ],
    "environment": [
      {
        "name": "PORT",
        "value": "8080"
      },
      {
        "name": "PYTHON_ENV",
        "value": "production"
      },
      {
        "name": "HF_HOME", 
        "value": "/tmp/huggingface_cache"
      }
    ],
    "logConfiguration": {
      "logDriver": "awslogs",
      "options": {
        "awslogs-group": "/ecs/gameforge-sdxl-optimized",
        "awslogs-region": "us-east-1",
        "awslogs-stream-prefix": "ecs"
      }
    },
    "healthCheck": {
      "command": [
        "CMD-SHELL",
        "curl -f http://localhost:8080/health || exit 1"
      ],
      "interval": 60,
      "timeout": 10,
      "retries": 3,
      "startPeriod": 300
    },
    "stopTimeout": 60
  }
]
